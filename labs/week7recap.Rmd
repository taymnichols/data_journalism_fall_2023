---
title: "week7_recap"
author: "Daniel Trielli"
date: "2023-10-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Turn off scientific notation
options(scipen=999)
```

## Loading the packages

Run the codeblock below to load the packages we will need for this recap

```{r}
library(tidyverse)
library(lubridate)
library(janitor)
```

## Load Data

Run the codeblock below to load the data.

```{r}
earthquakes <- read_csv('https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.csv')

#Setting time column as datetime
earthquakes <- earthquakes |> mutate(time = as_datetime(time))
```

#### Answer the questions below

Most questions have a code block and a space for an answer below. Write the code you think is necessary and, in the answer space, write out what you did and what was the result.

------------------------------------------------------------------------

#### **Q1** Look at the earthquakes dataset. Finish the sentence below as if you were explaining the data to someone who had not seen it before but needs to know about it.



**A1:** This dataset contains information about the date, time, location, magnitude, and other details about earthquakes, icequakes, and other types of geological events. It spans from 9/11/2023 to 10/11/2023.

------------------------------------------------------------------------

#### **Q2** How many records there are there in this dataset? What do they mean and what useful information we can gather from it, looking at the columns?

**A2:**
There are 9,774 records in this data set. They contain very specific information on earthquakes and other geological events. From a journalistic perspective, I would say the most useful or important pieces of information include the date, time, location, magnitude, location, and type of earthquake. We can also gather more in-depth data from this set on the latitude and longitude, depth, and other specifics of each earthquake. However this data I think would be more useful for scientists (although depth might be useful for us perhaps).

------------------------------------------------------------------------

#### **Q3** How do I reorganize this data to see the ones that are the deepest first? What is the depth that shows up for the deepest one, and its magnitude?

```{r}
earthquakes |>
  arrange(desc(depth))
```

**A3:**
The deepest earthquake was 670 km deep and was a 4.20 magnitude.

------------------------------------------------------------------------

#### **Q4** I just want to see the earthquakes with a magnitude larger than 6. How do I do that? And how many are there that fit this criteria?

```{r}
earthquakes |>
  filter(mag > 6) |>
  arrange(desc(mag))

```

**A4:**
There are 13 earthquakes with a magnitude higher than 6.

------------------------------------------------------------------------

#### **Q5** What about if I want to see earthquakes that have both a magnitude larger than 6 and a depth smaller than 20? How many are there in the data set that fit [both]{.underline} these criteria?

```{r}
earthquakes |>
  filter(mag > 6 & depth < 20) |>
  arrange(desc(mag))

```

**A5:**
There are six earthquakes with depths below 20 and a magnitude higher than 6.

------------------------------------------------------------------------

#### **Q6** What about if I want to see earthquakes that either have a magnitude larger than 6 OR a depth smaller than 20? How many are there in the data set that fit [either]{.underline} these criteria?

```{r}
earthquakes |>
  filter(mag > 6 | depth < 20) |>
  arrange(desc(mag))
```

**A6:**
There were 7,446 earthquakes with either a magnitude of more than 6 or a depth of less than 20 km.

------------------------------------------------------------------------

#### **Q7** I'm interested in finding earthquakes that took place in Alaska. Which column should I look at? How do I use it to find all the earthquakes in Alaska? How many earthquakes took place there?

```{r}
earthquakes |>
  filter(str_detect(place, "Alaska|alaska"))
```

**A7:**
There were 3,446 earthquake in Alaska in the past month.

------------------------------------------------------------------------

#### **Q8** I notice that there is a column called 'type', that seems to have different kinds of tremors. What is the best way to find what are all the possible types of tremors, and counting how many of each there are in this data set? What are the first two most common types of tremors in this data set?

```{r}
earthquakes |> 
  group_by(type) |>
  summarise(count = n())

```

**A8:**
The most common types of tremors are earthquakes and quarry blasts.

------------------------------------------------------------------------

#### **Q9** What is the average depth of the earthquake type in this data set? Is there anything that seems unusual or surprising in this finding?

```{r}
earthquakes |> 
  filter(type == "earthquake") |>
  summarise(mean(depth))
```

```{r}
earthquakes_only <- earthquakes |> 
 filter(type == "earthquake")

earthquakes_only |>
  summary(quartiles)
```

**A9:**
So after looking at the quartiles, a 25 km deep earthquake is actually deeper than at least 75% of earthquakes. The average is getting skewed by either a TON of shallow earthquakes or some VERY deep ones. There are some outliers there. Might be more useful to look at the median.
------------------------------------------------------------------------

#### **Q10** I'm interested, in the future, to see the hours in which earthquakes happen. How can I extract the hour from the time column?

```{r}
earthquakes <- earthquakes |>
  mutate(hour=hour(time))
```

**A10:**
You use lubridate to separate out hour in a new column.

------------------------------------------------------------------------

#### **Q11** I want to make a note of all the records in this data set that I consider serious. For my purposes, I'm thinking that all tremors that have a magnitude that is larger than 3 are serious. How do I automatically create a new column showing whether an earthquake is serious or not?

```{r}
earthquakes <- earthquakes |>
  mutate(concern_level =  case_when(
    (mag > 3) ~ "serious",
        .default = "not serious"))

```

**A11:**
You use case_when to make a new column.
------------------------------------------------------------------------

#### **Q12** I have no idea how earthquakes work and I'm interested in seeing if there is a particular time of day in which serious earthquakes happen. How can I see that condensed in a table with all the hours in a day and all the serious earthquakes in each hour? What is the hour with fewer serious earthquakes and the one with the most serious earthquakes?

```{r}
earthquakes |> 
  filter(concern_level == "serious") |>
  group_by(hour) |>
  summarise(count = n()) |>
  arrange(desc(count))
  

```

**A12**:

------------------------------------------------------------------------

#### **Q13** What's another question you are interested in and how would you ask it in R?

```{r}
earthquakes |> 
  filter(concern_level == "serious") |>
  group_by(locationSource) |>
  summarise(count = n()) |>
  arrange(desc(count))

```

### A13
I would like to look at what the top locations are for earthquakes. I'd have to take the time to write the extra code - is there a way to separate out state when the locations aren't uniform? This code doesn't quite get at what I want to look at, but it is a good start.